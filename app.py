# app.py
import os
import re
import html
import json
import datetime as dt
import requests
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components

# ---------- NAVER API ----------
API_BLOG  = "https://openapi.naver.com/v1/search/blog.json"
API_CAFE  = "https://openapi.naver.com/v1/search/cafearticle.json"
API_LOCAL = "https://openapi.naver.com/v1/search/local.json"
API_DATALAB_SEARCH = "https://openapi.naver.com/v1/datalab/search"
API_SHOP_CAT       = "https://openapi.naver.com/v1/datalab/shopping/categories"
API_SHOP_CAT_KW    = "https://openapi.naver.com/v1/datalab/shopping/category/keywords"

API_PAGE_SIZE  = 100          # ë¸”ë¡œê·¸/ì¹´í˜: ìµœëŒ€ 100
API_START_MAX  = 1000         # ë¸”ë¡œê·¸/ì¹´í˜: start ìµœëŒ€
DEFAULT_PAGE_SIZE = 20        # ë¸”ë¡œê·¸/ì¹´í˜ í•œ í™”ë©´ í‘œì‹œ
LOCAL_DISPLAY_MAX = 5         # ì§€ì—­: ë¬¸ì„œìƒ ìµœëŒ€ 5
LOCAL_START   = 1             # ì§€ì—­: start=1 (í˜ì´ì§• ì—†ìŒ)

# ---------- Creds ----------
def _secret_or_none(key: str):
    try:
        return st.secrets[key]
    except Exception:
        return None

def get_credentials():
    cid = os.environ.get("NAVER_CLIENT_ID")
    csec = os.environ.get("NAVER_CLIENT_SECRET")
    cid = _secret_or_none("NAVER_CLIENT_ID") or cid or ""
    csec = _secret_or_none("NAVER_CLIENT_SECRET") or csec or ""
    return cid, csec

def _auth_headers(content_json=False):
    cid, csec = get_credentials()
    if not cid or not csec:
        st.error(
            "NAVER_CLIENT_ID / NAVER_CLIENT_SECRETì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "â€¢ ë°©ë²• A: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.streamlit/secrets.toml`\n"
            "â€¢ ë°©ë²• B: í™˜ê²½ë³€ìˆ˜ NAVER_CLIENT_ID, NAVER_CLIENT_SECRET"
        )
        st.stop()
    headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec}
    if content_json:
        headers["Content-Type"] = "application/json"
    return headers

# ---------- Utils ----------
def strip_b_tags(text: str) -> str:
    if not isinstance(text, str):
        return text
    return re.sub(r"</?b>", "", text)

def emphasize_api_b(text: str) -> str:
    escaped = html.escape(text or "")
    return escaped.replace("&lt;b&gt;", "<mark>").replace("&lt;/b&gt;", "</mark>")

def build_highlighter(raw_query: str):
    terms = re.findall(r"[0-9A-Za-zê°€-í£]+", raw_query or "")
    terms = [t for t in terms if len(t) >= 2]
    if not terms:
        return lambda s: emphasize_api_b(s or "")
    pattern = re.compile("(" + "|".join(map(re.escape, terms)) + ")", re.IGNORECASE)
    def highlight(text: str) -> str:
        base = emphasize_api_b(text or "")
        return pattern.sub(r"<mark>\1</mark>", base)
    return highlight

# ---------- Caching helpers ----------
@st.cache_data(show_spinner=False, ttl=600)
def cached_get(url, headers, params):
    r = requests.get(url, headers=headers, params=params, timeout=15)
    return r.status_code, (r.json() if "application/json" in r.headers.get("Content-Type","") else r.text)

@st.cache_data(show_spinner=False, ttl=600)
def cached_post(url, headers, payload):
    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=20)
    return r.status_code, (r.json() if "application/json" in r.headers.get("Content-Type","") else r.text)

# ---------- Search API ê³µí†µ í˜¸ì¶œ ----------
def call_search(api_url: str, query: str, start: int, display: int, sort: str):
    headers = _auth_headers()
    params = {"query": query, "start": start, "display": display, "sort": sort}
    code, data = cached_get(api_url, headers, params)
    if code != 200:
        st.error(f"[ê²€ìƒ‰ API ì˜¤ë¥˜] {api_url} Â· HTTP {code}\n\n{data}")
        st.stop()
    return data

# ---------- ì •í™• ì¼ì¹˜ í•„í„°ìš© ìˆ˜ì§‘ (ë¸”ë¡œê·¸/ì¹´í˜ ê³µìš©) ----------
@st.cache_data(show_spinner=False, ttl=600)
def fetch_filtered_page(api_url: str, query: str, sort: str, page_size: int, page_index: int):
    """
    ì •í™• ì¼ì¹˜ ONì¼ ë•Œ:
    - ì œëª©/ìš”ì•½ì˜ <b> ì œê±° í›„ query 'ê·¸ëŒ€ë¡œ'(ëŒ€ì†Œë¬¸ì/ë„ì–´ì“°ê¸° í¬í•¨) í¬í•¨ í•­ëª©ë§Œ ëˆ„ì .
    - 1â†’1000 ë²”ìœ„ë¥¼ 100ê°œ ë‹¨ìœ„ë¡œ ê°€ì ¸ì™€ í•„ìš”í•œ í˜ì´ì§€ë§Œ ë°˜í™˜.
    """
    matched, target_fetch = [], page_index * page_size + 1
    headers = _auth_headers()
    for start in range(1, API_START_MAX + 1, API_PAGE_SIZE):
        code, data = cached_get(
            api_url, headers, {"query": query, "start": start, "display": API_PAGE_SIZE, "sort": sort}
        )
        if code != 200:
            break
        items = data.get("items", []) or []
        if not items: break
        for it in items:
            title_plain = strip_b_tags(it.get("title", "") or "")
            desc_plain  = strip_b_tags(it.get("description", "") or "")
            if (query in title_plain) or (query in desc_plain):
                matched.append(it)
                if len(matched) >= target_fetch: break
        if len(matched) >= target_fetch or len(items) < API_PAGE_SIZE:
            break

    s, e = (page_index - 1) * page_size, (page_index - 1) * page_size + page_size
    page_items = matched[s:e] if s < len(matched) else []
    has_next = len(matched) > e
    return page_items, has_next, len(matched)

# ---------- DataLab: í†µí•© ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ----------
def call_datalab_search_trend(
    keywords: list[str], start_date: str, end_date: str,
    time_unit: str = "date", device: str | None = None,
    ages: list[str] | None = None, gender: str | None = None,
):
    headers = _auth_headers(content_json=True)
    payload = {
        "startDate": start_date, "endDate": end_date, "timeUnit": time_unit,
        "keywordGroups": [{"groupName": kw, "keywords": [kw]} for kw in keywords if kw.strip()],
    }
    if device: payload["device"] = device
    if ages:   payload["ages"] = ages
    if gender: payload["gender"] = gender
    code, data = cached_post(API_DATALAB_SEARCH, headers, payload)
    if code != 200:
        st.error(f"[ë°ì´í„°ë©(ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ)] HTTP {code}\n\n{data}")
        st.stop()
    return data

def datalab_to_dataframe(data: dict) -> pd.DataFrame:
    results = data.get("results", [])
    frames = []
    for group in results:
        name = group.get("title") or group.get("keyword") or group.get("groupName") or "keyword"
        pts = group.get("data", []) or []
        if not pts: continue
        df = pd.DataFrame(pts)
        if "period" not in df.columns or "ratio" not in df.columns or df.empty: continue
        df = df.rename(columns={"ratio": name})
        frames.append(df[["period", name]])
    if not frames: return pd.DataFrame()
    base = frames[0]
    for f in frames[1:]: base = base.merge(f, on="period", how="outer")
    if "period" in base.columns: base = base.sort_values("period")
    return base.reset_index(drop=True)

# ---------- DataLab: ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ ----------
def call_shopping_categories(categories: list[tuple[str, str]], start_date: str, end_date: str,
                             time_unit: str = "date", device: str | None = None,
                             ages: list[str] | None = None, gender: str | None = None):
    headers = _auth_headers(content_json=True)
    payload = {
        "startDate": start_date, "endDate": end_date, "timeUnit": time_unit,
        "category": [{"name": nm, "param": [cid]} for (nm, cid) in categories if nm and cid],
    }
    if device: payload["device"] = device
    if ages:   payload["ages"] = ages
    if gender: payload["gender"] = gender
    code, data = cached_post(API_SHOP_CAT, headers, payload)
    if code != 200:
        st.error(f"[ì‡¼í•‘ì¸ì‚¬ì´íŠ¸-ë¶„ì•¼ë³„] HTTP {code}\n\n{data}")
        st.stop()
    return data

def call_shopping_category_keywords(category_id: str, keyword_pairs: list[tuple[str, str]],
                                    start_date: str, end_date: str, time_unit: str = "date",
                                    device: str | None = None, ages: list[str] | None = None,
                                    gender: str | None = None):
    headers = _auth_headers(content_json=True)
    payload = {
        "startDate": start_date, "endDate": end_date, "timeUnit": time_unit,
        "category": category_id,
        "keyword": [{"name": name, "param": [kw]} for (name, kw) in keyword_pairs if name and kw],
    }
    if device: payload["device"] = device
    if ages:   payload["ages"] = ages
    if gender: payload["gender"] = gender
    code, data = cached_post(API_SHOP_CAT_KW, headers, payload)
    if code != 200:
        st.error(f"[ì‡¼í•‘ì¸ì‚¬ì´íŠ¸-ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ] HTTP {code}\n\n{data}")
        st.stop()
    return data

def shopping_to_dataframe(data: dict) -> pd.DataFrame:
    results = data.get("results", [])
    frames = []
    for group in results:
        name = group.get("title") or "series"
        pts = group.get("data", []) or []
        if not pts: continue
        df = pd.DataFrame(pts)
        if "period" not in df.columns or "ratio" not in df.columns or df.empty: continue
        df = df.rename(columns={"ratio": name})
        frames.append(df[["period", name]])
    if not frames: return pd.DataFrame()
    base = frames[0]
    for f in frames[1:]: base = base.merge(f, on="period", how="outer")
    if "period" in base.columns: base = base.sort_values("period")
    return base.reset_index(drop=True)

# ---------- ê³µí†µ ë Œë” ----------
def render_table(items: list[dict], highlighter, author_key: str, author_label: str, show_date_key: str | None = None):
    if not items:
        components.html("<p style='color:#666'>í‘œì‹œí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.</p>", height=60)
        return
    rows_html = []
    for it in items:
        title_html = highlighter(it.get("title", ""))
        desc_html  = highlighter(it.get("description", ""))
        author     = html.escape(it.get(author_key, "") or "")
        date_val   = html.escape((it.get(show_date_key, "") or "")) if show_date_key else "-"
        url        = html.escape(it.get("link", "") or "")
        row = f"""
<tr>
  <td style="padding:8px 10px;vertical-align:top;min-width:240px;">
    <a href="{url}" target="_blank" style="text-decoration:none;">{title_html}</a>
  </td>
  <td style="padding:8px 10px;vertical-align:top;">{desc_html}</td>
  <td style="padding:8px 10px;vertical-align:top;white-space:nowrap;">{author}</td>
  <td style="padding:8px 10px;vertical-align:top;white-space:nowrap;">{date_val}</td>
  <td style="padding:8px 10px;vertical-align:top;white-space:nowrap;"><a href="{url}" target="_blank">ì—´ê¸°</a></td>
</tr>
"""
        rows_html.append(row)
    table_html = f"""
<!doctype html>
<html>
<head><meta charset="utf-8"/>
<style>
  table {{ width:100%; border-collapse:collapse; border:1px solid #e5e7eb; }}
  thead tr {{ background:#f8fafc; }}
  th, td {{ text-align:left; padding:10px; border-bottom:1px solid #e5e7eb; }}
  mark {{ background: #fff3a3; padding: 0 2px; }}
</style>
</head>
<body>
<div style="max-width:100%; overflow:auto;">
  <table>
    <thead>
      <tr>
        <th>ì œëª©</th><th>ìš”ì•½</th><th>{author_label}</th><th>ì‘ì„±ì¼</th><th>URL</th>
      </tr>
    </thead>
    <tbody>
      {''.join(rows_html)}
    </tbody>
  </table>
</div>
</body>
</html>
"""
    rows_to_show = min(len(items), DEFAULT_PAGE_SIZE)
    table_height = int(34 * rows_to_show + 40 + 20)
    components.html(table_html, height=table_height + 200, scrolling=True)

def render_local_table(items: list[dict], highlighter):
    if not items:
        components.html("<p style='color:#666'>í‘œì‹œí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.</p>", height=60)
        return
    rows_html = []
    for it in items:
        title_html = highlighter(it.get("title", ""))
        category   = emphasize_api_b(it.get("category", ""))
        desc_html  = highlighter(it.get("description", ""))
        addr       = html.escape(it.get("address", "") or "")
        road       = html.escape(it.get("roadAddress", "") or "")
        url        = html.escape(it.get("link", "") or "")
        row = f"""
<tr>
  <td style="padding:8px 10px;vertical-align:top;min-width:200px;">{title_html}</td>
  <td style="padding:8px 10px;vertical-align:top;white-space:nowrap;">{category}</td>
  <td style="padding:8px 10px;vertical-align:top;">{desc_html}</td>
  <td style="padding:8px 10px;vertical-align:top;"><div>{addr}</div><div style="color:#555;">{road}</div></td>
  <td style="padding:8px 10px;vertical-align:top;white-space:nowrap;"><a href="{url}" target="_blank">ì—´ê¸°</a></td>
</tr>
"""
        rows_html.append(row)
    table_html = f"""
<!doctype html>
<html>
<head><meta charset="utf-8"/>
<style>
  table {{ width:100%; border-collapse:collapse; border:1px solid #e5e7eb; }}
  thead tr {{ background:#f8fafc; }}
  th, td {{ text-align:left; padding:10px; border-bottom:1px solid #e5e7eb; }}
  mark {{ background: #fff3a3; padding: 0 2px; }}
</style>
</head>
<body>
<div style="max-width:100%; overflow:auto;">
  <table>
    <thead>
      <tr>
        <th>ì—…ì²´ëª…</th><th>ì¹´í…Œê³ ë¦¬</th><th>ì„¤ëª…</th><th>ì£¼ì†Œ(ì§€ë²ˆ/ë„ë¡œëª…)</th><th>URL</th>
      </tr>
    </thead>
    <tbody>
      {''.join(rows_html)}
    </tbody>
  </table>
</div>
</body>
</html>
"""
    rows_to_show = len(items)
    table_height = int(34 * rows_to_show + 40 + 20)
    components.html(table_html, height=table_height + 160, scrolling=True)

# ================== Streamlit App ==================
def main():
    st.set_page_config(page_title="NAVER í†µí•© ê²€ìƒ‰ (ë¸”ë¡œê·¸/ì¹´í˜/ì§€ì—­/ë°ì´í„°ë©/ì‡¼í•‘)", page_icon="ğŸ”", layout="wide")
    st.title("ğŸ” NAVER í†µí•© ê²€ìƒ‰ (ë¸”ë¡œê·¸ / ì¹´í˜ê¸€ / ì§€ì—­ / ë°ì´í„°ë© / ì‡¼í•‘ì¸ì‚¬ì´íŠ¸)")

    # Sidebar: credentials
    with st.sidebar:
        st.markdown("**ìê²©ì¦ëª… ì„¤ì •**")
        cid_default, csec_default = get_credentials()
        cid_input = st.text_input("NAVER_CLIENT_ID", value=cid_default, type="password")
        csec_input = st.text_input("NAVER_CLIENT_SECRET", value=csec_default, type="password")
        if cid_input and csec_input and (
            cid_input != os.environ.get("NAVER_CLIENT_ID") or
            csec_input != os.environ.get("NAVER_CLIENT_SECRET")
        ):
            os.environ["NAVER_CLIENT_ID"] = cid_input
            os.environ["NAVER_CLIENT_SECRET"] = csec_input
            st.info("í˜„ì¬ ì„¸ì…˜ì— ìê²©ì¦ëª…ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.")
        st.markdown("---")
        st.caption("ë™ì¼ íŒŒë¼ë¯¸í„°ëŠ” ìºì‹œë˜ì–´ ì¿¼í„° ì‚¬ìš©ì„ ì¤„ì…ë‹ˆë‹¤. (10ë¶„ TTL)")

    # ê³µí†µ ê²€ìƒ‰ì–´
    query = st.text_input("ê³µí†µ ê²€ìƒ‰ì–´ (ë¸”ë¡œê·¸/ì¹´í˜/ì§€ì—­/íŠ¸ë Œë“œ/ì‡¼í•‘)", value="ë¦¬ë·° ìë™í™”")

    # ìƒíƒœ ì´ˆê¸°í™”: ê²€ìƒ‰ì–´ê°€ ë°”ë€Œë©´ í˜ì´ì§•/ìƒíƒœ ë¦¬ì…‹
    if "last_query" not in st.session_state:
        st.session_state.last_query = query
    if query != st.session_state.last_query:
        for k, v in [
            ("blog_start", 1), ("blog_page", 1),
            ("cafe_start", 1), ("cafe_page", 1),
        ]:
            st.session_state[k] = v
        st.session_state.last_query = query

    # íƒ­
    tab_blog, tab_cafe, tab_trend, tab_local, tab_shop = st.tabs(
        ["ë¸”ë¡œê·¸", "ì¹´í˜ê¸€", "ë°ì´í„°ë©(ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ)", "ì§€ì—­", "ì‡¼í•‘ì¸ì‚¬ì´íŠ¸"]
    )

    # ===== ë¸”ë¡œê·¸ =====
    with tab_blog:
        st.subheader("ë¸”ë¡œê·¸ ê²€ìƒ‰")
        bc1, bc2, bc3 = st.columns([1, 1, 1])
        with bc1:
            blog_sort = st.selectbox("ì •ë ¬", options=[("sim", "ì •í™•ë„ìˆœ"), ("date", "ë‚ ì§œìˆœ")],
                                     index=0, format_func=lambda x: x[1], key="blog_sort")[0]
        with bc2:
            blog_page_size = st.number_input("í•œ í˜ì´ì§€ ê²°ê³¼(1~100)", 1, 100, DEFAULT_PAGE_SIZE, 1, key="blog_ps")
        with bc3:
            blog_exact = st.toggle("ì •í™• ì¼ì¹˜ í•„í„°", value=True, key="blog_exact",
                                   help="ì œëª©/ìš”ì•½ì— ê²€ìƒ‰ì–´ê°€ ê·¸ëŒ€ë¡œ(ë„ì–´ì“°ê¸° í¬í•¨) ì¡´ì¬í•˜ëŠ” í•­ëª©ë§Œ í‘œì‹œ(ëŒ€ì†Œë¬¸ì êµ¬ë¶„)")

        if "blog_start" not in st.session_state: st.session_state.blog_start = 1
        if "blog_page" not in st.session_state:  st.session_state.blog_page = 1

        highlighter = build_highlighter(query)
        if blog_exact:
            items, has_next, matched_cnt = fetch_filtered_page(
                API_BLOG, query, blog_sort, int(blog_page_size), st.session_state.blog_page
            )
            info = f"í•„í„° ëª¨ë“œ Â· ì •í™• ì¼ì¹˜ ëˆ„ì  {matched_cnt:,}ê±´(â‰¤1,000) Â· {st.session_state.blog_page} í˜ì´ì§€"
            prev_disabled = st.session_state.blog_page <= 1
            next_disabled = not has_next
        else:
            data = call_search(API_BLOG, query, st.session_state.blog_start, int(blog_page_size), blog_sort)
            total = data.get("total", 0)
            start_now = data.get("start", st.session_state.blog_start)
            items = data.get("items", []) or []
            info = f"ì¼ë°˜ ëª¨ë“œ Â· API ì´ {total:,}ê±´ Â· í‘œì‹œ {start_now}~{min(start_now + int(blog_page_size) - 1, total):,}"
            prev_disabled = st.session_state.blog_start <= 1
            next_disabled = (st.session_state.blog_start + int(blog_page_size) > min(total, API_START_MAX))

        st.caption(info)
        render_table(items, highlighter, author_key="bloggername", author_label="ë¸”ë¡œê±°", show_date_key="postdate")

        l, m, r = st.columns(3)
        with l:
            if st.button("â¬… ì´ì „", key="blog_prev", disabled=prev_disabled):
                if blog_exact: st.session_state.blog_page = max(1, st.session_state.blog_page - 1)
                else:          st.session_state.blog_start = max(1, st.session_state.blog_start - int(blog_page_size))
                st.rerun()
        with m:
            st.caption(f"{'í•„í„°' if blog_exact else 'ì¼ë°˜'} Â· "
                       f"{'page='+str(st.session_state.blog_page) if blog_exact else 'start='+str(st.session_state.blog_start)}")
        with r:
            if st.button("ë‹¤ìŒ â¡", key="blog_next", disabled=next_disabled):
                if blog_exact: st.session_state.blog_page += 1
                else:          st.session_state.blog_start += int(blog_page_size)
                st.rerun()

        if items:
            df = pd.DataFrame({
                "ì œëª©": [strip_b_tags(it.get("title","")) for it in items],
                "ìš”ì•½": [strip_b_tags(it.get("description","")) for it in items],
                "ë¸”ë¡œê±°": [it.get("bloggername","") for it in items],
                "ì‘ì„±ì¼": [it.get("postdate","") for it in items],
                "URL": [it.get("link","") for it in items],
            })
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ(ë¸”ë¡œê·¸)", data=df.to_csv(index=False),
                               file_name="naver_blog_results.csv", mime="text/csv")

    # ===== ì¹´í˜ê¸€ =====
    with tab_cafe:
        st.subheader("ì¹´í˜ê¸€ ê²€ìƒ‰")
        cc1, cc2, cc3 = st.columns([1, 1, 1])
        with cc1:
            cafe_sort = st.selectbox("ì •ë ¬", options=[("sim", "ì •í™•ë„ìˆœ"), ("date", "ë‚ ì§œìˆœ")],
                                     index=0, format_func=lambda x: x[1], key="cafe_sort")[0]
        with cc2:
            cafe_page_size = st.number_input("í•œ í˜ì´ì§€ ê²°ê³¼(1~100)", 1, 100, DEFAULT_PAGE_SIZE, 1, key="cafe_ps")
        with cc3:
            cafe_exact = st.toggle("ì •í™• ì¼ì¹˜ í•„í„°", value=True, key="cafe_exact",
                                   help="ì œëª©/ìš”ì•½ì— ê²€ìƒ‰ì–´ê°€ ê·¸ëŒ€ë¡œ ì¡´ì¬ (ëŒ€ì†Œë¬¸ì/ë„ì–´ì“°ê¸° í¬í•¨)")

        if "cafe_start" not in st.session_state: st.session_state.cafe_start = 1
        if "cafe_page" not in st.session_state:  st.session_state.cafe_page = 1

        highlighter = build_highlighter(query)
        if cafe_exact:
            items, has_next, matched_cnt = fetch_filtered_page(
                API_CAFE, query, cafe_sort, int(cafe_page_size), st.session_state.cafe_page
            )
            info = f"í•„í„° ëª¨ë“œ Â· ì •í™• ì¼ì¹˜ ëˆ„ì  {matched_cnt:,}ê±´(â‰¤1,000) Â· {st.session_state.cafe_page} í˜ì´ì§€"
            prev_disabled = st.session_state.cafe_page <= 1
            next_disabled = not has_next
        else:
            data = call_search(API_CAFE, query, st.session_state.cafe_start, int(cafe_page_size), cafe_sort)
            total = data.get("total", 0)
            start_now = data.get("start", st.session_state.cafe_start)
            items = data.get("items", []) or []
            info = f"ì¼ë°˜ ëª¨ë“œ Â· API ì´ {total:,}ê±´ Â· í‘œì‹œ {start_now}~{min(start_now + int(cafe_page_size) - 1, total):,}"
            prev_disabled = st.session_state.cafe_start <= 1
            next_disabled = (st.session_state.cafe_start + int(cafe_page_size) > min(total, API_START_MAX))

        st.caption(info)
        render_table(items, highlighter, author_key="cafename", author_label="ì¹´í˜", show_date_key=None)

        l, m, r = st.columns(3)
        with l:
            if st.button("â¬… ì´ì „", key="cafe_prev", disabled=prev_disabled):
                if cafe_exact: st.session_state.cafe_page = max(1, st.session_state.cafe_page - 1)
                else:          st.session_state.cafe_start = max(1, st.session_state.cafe_start - int(cafe_page_size))
                st.rerun()
        with m:
            st.caption(f"{'í•„í„°' if cafe_exact else 'ì¼ë°˜'} Â· "
                       f"{'page='+str(st.session_state.cafe_page) if cafe_exact else 'start='+str(st.session_state.cafe_start)}")
        with r:
            if st.button("ë‹¤ìŒ â¡", key="cafe_next", disabled=next_disabled):
                if cafe_exact: st.session_state.cafe_page += 1
                else:          st.session_state.cafe_start += int(cafe_page_size)
                st.rerun()

        if items:
            df = pd.DataFrame({
                "ì œëª©": [strip_b_tags(it.get("title","")) for it in items],
                "ìš”ì•½": [strip_b_tags(it.get("description","")) for it in items],
                "ì¹´í˜": [it.get("cafename","") for it in items],
                "ì‘ì„±ì¼": ["" for _ in items],
                "URL": [it.get("link","") for it in items],
            })
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ(ì¹´í˜ê¸€)", data=df.to_csv(index=False),
                               file_name="naver_cafe_results.csv", mime="text/csv")

    # ===== ë°ì´í„°ë©(ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ) =====
    with tab_trend:
        st.subheader("ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ (ë°ì´í„°ë©)")
        tk1, tk2 = st.columns([2, 1])
        with tk1:
            trend_keywords_raw = st.text_input("íŠ¸ë Œë“œ í‚¤ì›Œë“œë“¤(ì‰¼í‘œë¡œ ë¶„ë¦¬) - ë¹„ìš°ë©´ ê³µí†µ ê²€ìƒ‰ì–´ ì‚¬ìš©", value="", key="trend_kw")
        with tk2:
            time_unit = st.selectbox("ë‹¨ìœ„", options=["date", "week", "month"], index=0, key="trend_tu")

        today = dt.date.today()
        default_start = today - dt.timedelta(days=90)
        t1, t2, t3 = st.columns([1, 1, 1])
        with t1:
            start_date = st.date_input("ì‹œì‘ì¼", value=default_start, max_value=today, key="trend_start")
        with t2:
            end_date = st.date_input("ì¢…ë£Œì¼", value=today, max_value=today, key="trend_end")
        with t3:
            device = st.selectbox("ë””ë°”ì´ìŠ¤", options=["ì „ì²´", "pc", "mo"], index=0, key="trend_dev")
        u1, u2 = st.columns([1, 1])
        with u1:
            gender = st.selectbox("ì„±ë³„", options=["ì „ì²´", "m", "f"], index=0, key="trend_gender")
        with u2:
            ages = st.multiselect("ì—°ë ¹ëŒ€", options=["10","20","30","40","50","60"], key="trend_ages")

        keywords = (
            [k.strip() for k in trend_keywords_raw.split(",") if k.strip()]
            if trend_keywords_raw.strip()
            else ([query.strip()] if query.strip() else [])
        )

        if keywords:
            dl_device = None if device == "ì „ì²´" else device
            dl_gender = None if gender == "ì „ì²´" else gender
            start_str = start_date.strftime("%Y-%m-%d")
            end_str = end_date.strftime("%Y-%m-%d")
            dl_data = call_datalab_search_trend(
                keywords=keywords, start_date=start_str, end_date=end_str,
                time_unit=time_unit, device=dl_device, ages=ages if ages else None, gender=dl_gender,
            )
            dl_df = datalab_to_dataframe(dl_data)
            if dl_df.empty or "period" not in dl_df.columns:
                st.info("í‘œì‹œí•  íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í‚¤ì›Œë“œ/ê¸°ê°„ í™•ì¸)")
            else:
                st.dataframe(dl_df, use_container_width=True, hide_index=True)
                st.line_chart(dl_df.set_index("period"))
        else:
            st.info("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # ===== ì§€ì—­ =====
    with tab_local:
        st.subheader("ì§€ì—­ ê²€ìƒ‰")
        lc1, lc2 = st.columns([1, 1])
        with lc1:
            local_sort = st.selectbox("ì •ë ¬", options=[("random", "ì •í™•ë„ìˆœ"), ("comment", "ë¦¬ë·° ë§ì€ ìˆœ")],
                                      index=0, format_func=lambda x: x[1], key="local_sort")[0]
        with lc2:
            st.number_input("í‘œì‹œ ê°œìˆ˜(ìµœëŒ€ 5)", min_value=1, max_value=5, value=LOCAL_DISPLAY_MAX, step=1, disabled=True)

        if query:
            highlighter = build_highlighter(query)
            data = call_search(API_LOCAL, query, LOCAL_START, LOCAL_DISPLAY_MAX, local_sort)
            items = data.get("items", []) or []
            st.caption("ì§€ì—­ APIëŠ” ë¬¸ì„œ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ 5ê±´ë§Œ ë°˜í™˜í•˜ë©° í˜ì´ì§•ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            render_local_table(items, highlighter)
            if items:
                df = pd.DataFrame({
                    "ì—…ì²´ëª…": [strip_b_tags(it.get("title","")) for it in items],
                    "ì¹´í…Œê³ ë¦¬": [strip_b_tags(it.get("category","")) for it in items],
                    "ì„¤ëª…": [strip_b_tags(it.get("description","")) for it in items],
                    "ì§€ë²ˆì£¼ì†Œ": [it.get("address","") for it in items],
                    "ë„ë¡œëª…ì£¼ì†Œ": [it.get("roadAddress","") for it in items],
                    "URL": [it.get("link","") for it in items],
                    "mapx": [it.get("mapx","") for it in items],
                    "mapy": [it.get("mapy","") for it in items],
                })
                st.download_button("CSV ë‹¤ìš´ë¡œë“œ(ì§€ì—­)", data=df.to_csv(index=False),
                                   file_name="naver_local_results.csv", mime="text/csv")
        else:
            st.info("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # ===== ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ =====
    with tab_shop:
        st.subheader("ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ (ë°ì´í„°ë©)")
        mode = st.radio("ë³´ê¸° ìœ í˜•", ["ë¶„ì•¼ë³„ íŠ¸ë Œë“œ", "ì¹´í…Œê³ ë¦¬ ë‚´ í‚¤ì›Œë“œë³„ íŠ¸ë Œë“œ"], horizontal=True, key="shop_mode")

        today = dt.date.today()
        default_start = today - dt.timedelta(days=90)
        c1, c2, c3 = st.columns([1, 1, 1])
        with c1:
            shop_start = st.date_input("ì‹œì‘ì¼", value=default_start, max_value=today, key="shop_start")
        with c2:
            shop_end = st.date_input("ì¢…ë£Œì¼", value=today, max_value=today, key="shop_end")
        with c3:
            shop_timeunit = st.selectbox("ë‹¨ìœ„", options=["date", "week", "month"], index=0, key="shop_tu")

        s1, s2, s3 = st.columns([1, 1, 1])
        with s1:
            shop_device = st.selectbox("ë””ë°”ì´ìŠ¤", options=["ì „ì²´", "pc", "mo"], index=0, key="shop_dev")
        with s2:
            shop_gender = st.selectbox("ì„±ë³„", options=["ì „ì²´", "m", "f"], index=0, key="shop_gender")
        with s3:
            shop_ages = st.multiselect("ì—°ë ¹ëŒ€", options=["10","20","30","40","50","60"], key="shop_ages")

        if mode == "ë¶„ì•¼ë³„ íŠ¸ë Œë“œ":
            st.caption("ë¶„ì•¼ ì½”ë“œ(cat_id)ëŠ” ë„¤ì´ë²„ì‡¼í•‘ ì¹´í…Œê³ ë¦¬ URLì˜ cat_id ê°’ì…ë‹ˆë‹¤. ìµœëŒ€ 3ê°œ.")
            raw = st.text_input("ë¶„ì•¼ ì´ë¦„=ì½”ë“œ(ì‰¼í‘œ ì—¬ëŸ¬ ê°œ). ì˜ˆ) íŒ¨ì…˜ì˜ë¥˜=50000000, í™”ì¥í’ˆ/ë¯¸ìš©=50000002", value="", key="shop_cat_raw")
            pairs = []
            for token in [t.strip() for t in raw.split(",") if t.strip()]:
                if "=" in token:
                    nm, cid = token.split("=", 1)
                    pairs.append((nm.strip(), cid.strip()))
            if pairs:
                start_str = shop_start.strftime("%Y-%m-%d")
                end_str   = shop_end.strftime("%Y-%m-%d")
                dev = None if shop_device == "ì „ì²´" else shop_device
                gen = None if shop_gender == "ì „ì²´" else shop_gender
                ages = shop_ages if shop_ages else None
                data = call_shopping_categories(
                    categories=pairs, start_date=start_str, end_date=end_str,
                    time_unit=shop_timeunit, device=dev, ages=ages, gender=gen
                )
                df = shopping_to_dataframe(data)
                if df.empty or "period" not in df.columns:
                    st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë¶„ì•¼ ì½”ë“œ/ê¸°ê°„ í™•ì¸)")
                else:
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    st.line_chart(df.set_index("period"))
                    st.download_button("CSV ë‹¤ìš´ë¡œë“œ(ì‡¼í•‘Â·ë¶„ì•¼ë³„)", data=df.to_csv(index=False),
                                       file_name="naver_shopping_categories.csv", mime="text/csv")
            else:
                st.info("â€˜ë¶„ì•¼ ì´ë¦„=ì½”ë“œâ€™ í˜•ì‹ìœ¼ë¡œ 1ê°œ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.caption("í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬(cat_id)ì™€ ë¹„êµí•  í‚¤ì›Œë“œ(ìµœëŒ€ 5ê°œ)ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.")
            cat_id = st.text_input("ì¹´í…Œê³ ë¦¬ ì½”ë“œ(cat_id). ì˜ˆ) 50000000", value="", key="shop_catid")
            kw_raw = st.text_input("í‚¤ì›Œë“œê·¸ë£¹ ì´ë¦„=ê²€ìƒ‰ì–´ (ì‰¼í‘œ ì—¬ëŸ¬ ê°œ). ì˜ˆ) ì •ì¥=ì •ì¥, ë¹„ì¦ˆë‹ˆìŠ¤ìºì£¼ì–¼=ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼", value="", key="shop_kw_raw")
            pairs = []
            for token in [t.strip() for t in kw_raw.split(",") if t.strip()]:
                if "=" in token:
                    nm, kw = token.split("=", 1)
                    pairs.append((nm.strip(), kw.strip()))
            if cat_id and pairs:
                start_str = shop_start.strftime("%Y-%m-%d")
                end_str   = shop_end.strftime("%Y-%m-%d")
                dev = None if shop_device == "ì „ì²´" else shop_device
                gen = None if shop_gender == "ì „ì²´" else shop_gender
                ages = shop_ages if shop_ages else None
                data = call_shopping_category_keywords(
                    category_id=cat_id, keyword_pairs=pairs, start_date=start_str, end_date=end_str,
                    time_unit=shop_timeunit, device=dev, ages=ages, gender=gen
                )
                df = shopping_to_dataframe(data)
                if df.empty or "period" not in df.columns:
                    st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì¹´í…Œê³ ë¦¬/í‚¤ì›Œë“œ/ê¸°ê°„ í™•ì¸)")
                else:
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    st.line_chart(df.set_index("period"))
                    st.download_button("CSV ë‹¤ìš´ë¡œë“œ(ì‡¼í•‘Â·í‚¤ì›Œë“œ)", data=df.to_csv(index=False),
                                       file_name="naver_shopping_keywords.csv", mime="text/csv")
            else:
                st.info("ì¹´í…Œê³ ë¦¬ ì½”ë“œì™€ â€˜ê·¸ë£¹ì´ë¦„=ê²€ìƒ‰ì–´â€™ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    st.caption("â€» ì¡°íšŒëŠ” ìë™ ì‹¤í–‰ë˜ë©°, ë™ì¼ íŒŒë¼ë¯¸í„° ì¬í˜¸ì¶œì€ ìºì‹œ(10ë¶„)ë˜ì–´ ì¿¼í„°ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤. ë¸”ë¡œê·¸/ì¹´í˜ëŠ” startâ‰¤1000 ì œì•½, ì§€ì—­ì€ ìµœëŒ€ 5ê±´, DataLab/ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ì˜ ratioëŠ” ì§‘í•© ë‚´ ìµœëŒ€=100 ê¸°ì¤€ ìƒëŒ€ê°’ì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
